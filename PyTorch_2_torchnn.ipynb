{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 2 - torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:<br>\n",
    "* [torch.nn tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "* [torch.nn docs](https://pytorch.org/docs/stable/nn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check version number\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if CUDA/GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CUDA/GPU is available print CUDA version\n",
    "if torch.cuda.is_available(): torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class instance\n",
    "lin = nn.Linear(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0786,  0.1508, -0.2231, -0.0703, -0.1125, -0.1226,  0.1040,  0.2447,\n",
       "          -0.0353,  0.3150],\n",
       "         [-0.0417, -0.1711, -0.2525, -0.1121,  0.0269, -0.1992,  0.1088, -0.0654,\n",
       "          -0.1672, -0.0131],\n",
       "         [-0.0151,  0.1263,  0.0325, -0.1861,  0.0098,  0.1111,  0.2114, -0.2393,\n",
       "           0.0044,  0.2168],\n",
       "         [ 0.2788,  0.0582,  0.2022, -0.1853, -0.1113,  0.2044,  0.2381,  0.0133,\n",
       "          -0.2733,  0.1778],\n",
       "         [ 0.0939,  0.2405,  0.0915,  0.2111,  0.3146,  0.2002, -0.1735, -0.2658,\n",
       "           0.2496, -0.0460]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.2975,  0.2421, -0.3009, -0.0732,  0.2276], requires_grad=True))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access weights and biases\n",
    "lin.weight, lin.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0786,  0.1508, -0.2231, -0.0703, -0.1125, -0.1226,  0.1040,  0.2447,\n",
       "         -0.0353,  0.3150],\n",
       "        [-0.0417, -0.1711, -0.2525, -0.1121,  0.0269, -0.1992,  0.1088, -0.0654,\n",
       "         -0.1672, -0.0131],\n",
       "        [-0.0151,  0.1263,  0.0325, -0.1861,  0.0098,  0.1111,  0.2114, -0.2393,\n",
       "          0.0044,  0.2168],\n",
       "        [ 0.2788,  0.0582,  0.2022, -0.1853, -0.1113,  0.2044,  0.2381,  0.0133,\n",
       "         -0.2733,  0.1778],\n",
       "        [ 0.0939,  0.2405,  0.0915,  0.2111,  0.3146,  0.2002, -0.1735, -0.2658,\n",
       "          0.2496, -0.0460]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add \".data\" to only get the data\n",
    "# .item() gets a Python number from a tensor containing a single value.\n",
    "lin.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__idiv__',\n",
       " '__ilshift__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rfloordiv__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_backward_hooks',\n",
       " '_base',\n",
       " '_cdata',\n",
       " '_coalesced_',\n",
       " '_dimI',\n",
       " '_dimV',\n",
       " '_grad',\n",
       " '_grad_fn',\n",
       " '_indices',\n",
       " '_make_subclass',\n",
       " '_nnz',\n",
       " '_values',\n",
       " '_version',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'add',\n",
       " 'add_',\n",
       " 'addbmm',\n",
       " 'addbmm_',\n",
       " 'addcdiv',\n",
       " 'addcdiv_',\n",
       " 'addcmul',\n",
       " 'addcmul_',\n",
       " 'addmm',\n",
       " 'addmm_',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'addr_',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'any',\n",
       " 'apply_',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan2_',\n",
       " 'atan_',\n",
       " 'backward',\n",
       " 'baddbmm',\n",
       " 'baddbmm_',\n",
       " 'bernoulli',\n",
       " 'bernoulli_',\n",
       " 'bincount',\n",
       " 'bmm',\n",
       " 'btrifact',\n",
       " 'btrifact_with_info',\n",
       " 'btrisolve',\n",
       " 'byte',\n",
       " 'cauchy_',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'char',\n",
       " 'cholesky',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contiguous',\n",
       " 'copy_',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'cuda',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'data_ptr',\n",
       " 'dense_dim',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'digamma',\n",
       " 'digamma_',\n",
       " 'dim',\n",
       " 'dist',\n",
       " 'div',\n",
       " 'div_',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'eig',\n",
       " 'element_size',\n",
       " 'eq',\n",
       " 'eq_',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'erfinv_',\n",
       " 'exp',\n",
       " 'exp_',\n",
       " 'expand',\n",
       " 'expand_as',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'exponential_',\n",
       " 'fft',\n",
       " 'fill_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'fmod',\n",
       " 'fmod_',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'gather',\n",
       " 'ge',\n",
       " 'ge_',\n",
       " 'gels',\n",
       " 'geometric_',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'gesv',\n",
       " 'get_device',\n",
       " 'grad',\n",
       " 'grad_fn',\n",
       " 'gt',\n",
       " 'gt_',\n",
       " 'half',\n",
       " 'hardshrink',\n",
       " 'histc',\n",
       " 'ifft',\n",
       " 'index_add',\n",
       " 'index_add_',\n",
       " 'index_copy',\n",
       " 'index_copy_',\n",
       " 'index_fill',\n",
       " 'index_fill_',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'int',\n",
       " 'inverse',\n",
       " 'irfft',\n",
       " 'is_coalesced',\n",
       " 'is_complex',\n",
       " 'is_contiguous',\n",
       " 'is_cuda',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_leaf',\n",
       " 'is_nonzero',\n",
       " 'is_pinned',\n",
       " 'is_same_size',\n",
       " 'is_set_to',\n",
       " 'is_shared',\n",
       " 'is_signed',\n",
       " 'is_sparse',\n",
       " 'isclose',\n",
       " 'item',\n",
       " 'kthvalue',\n",
       " 'layout',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'lerp',\n",
       " 'lerp_',\n",
       " 'lgamma',\n",
       " 'lgamma_',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_normal_',\n",
       " 'log_softmax',\n",
       " 'logdet',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lt',\n",
       " 'lt_',\n",
       " 'map2_',\n",
       " 'map_',\n",
       " 'masked_fill',\n",
       " 'masked_fill_',\n",
       " 'masked_scatter',\n",
       " 'masked_scatter_',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_power',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'mul_',\n",
       " 'multinomial',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'mvlgamma_',\n",
       " 'name',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'ndimension',\n",
       " 'ne',\n",
       " 'ne_',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'nelement',\n",
       " 'new',\n",
       " 'new_empty',\n",
       " 'new_full',\n",
       " 'new_ones',\n",
       " 'new_tensor',\n",
       " 'new_zeros',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'normal_',\n",
       " 'numel',\n",
       " 'numpy',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'output_nr',\n",
       " 'permute',\n",
       " 'pin_memory',\n",
       " 'pinverse',\n",
       " 'polygamma',\n",
       " 'polygamma_',\n",
       " 'potrf',\n",
       " 'potri',\n",
       " 'potrs',\n",
       " 'pow',\n",
       " 'pow_',\n",
       " 'prelu',\n",
       " 'prod',\n",
       " 'pstrf',\n",
       " 'put_',\n",
       " 'qr',\n",
       " 'random_',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'record_stream',\n",
       " 'register_hook',\n",
       " 'reinforce',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'remainder_',\n",
       " 'renorm',\n",
       " 'renorm_',\n",
       " 'repeat',\n",
       " 'requires_grad',\n",
       " 'requires_grad_',\n",
       " 'reshape',\n",
       " 'reshape_as',\n",
       " 'resize',\n",
       " 'resize_',\n",
       " 'resize_as',\n",
       " 'resize_as_',\n",
       " 'retain_grad',\n",
       " 'rfft',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'scatter',\n",
       " 'scatter_',\n",
       " 'scatter_add',\n",
       " 'scatter_add_',\n",
       " 'select',\n",
       " 'set_',\n",
       " 'shape',\n",
       " 'share_memory_',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'sign_',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'size',\n",
       " 'slogdet',\n",
       " 'smm',\n",
       " 'softmax',\n",
       " 'sort',\n",
       " 'sparse_dim',\n",
       " 'sparse_mask',\n",
       " 'sparse_resize_',\n",
       " 'sparse_resize_and_clear_',\n",
       " 'split',\n",
       " 'split_with_sizes',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'squeeze',\n",
       " 'squeeze_',\n",
       " 'sspaddmm',\n",
       " 'std',\n",
       " 'stft',\n",
       " 'storage',\n",
       " 'storage_offset',\n",
       " 'storage_type',\n",
       " 'stride',\n",
       " 'sub',\n",
       " 'sub_',\n",
       " 'sum',\n",
       " 'svd',\n",
       " 'symeig',\n",
       " 't',\n",
       " 't_',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'to',\n",
       " 'to_dense',\n",
       " 'to_sparse',\n",
       " 'tolist',\n",
       " 'topk',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'transpose_',\n",
       " 'tril',\n",
       " 'tril_',\n",
       " 'triu',\n",
       " 'triu_',\n",
       " 'trtrs',\n",
       " 'trunc',\n",
       " 'trunc_',\n",
       " 'type',\n",
       " 'type_as',\n",
       " 'unbind',\n",
       " 'unfold',\n",
       " 'uniform_',\n",
       " 'unique',\n",
       " 'unsqueeze',\n",
       " 'unsqueeze_',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'view_as',\n",
       " 'where',\n",
       " 'zero_']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lin.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07858554,  0.15084133, -0.22308512, -0.07028814, -0.11254464,\n",
       "        -0.12259689,  0.10402086,  0.24473402, -0.03530282,  0.31502452],\n",
       "       [-0.0416517 , -0.17113034, -0.25251487, -0.11211117,  0.0268513 ,\n",
       "        -0.19919854,  0.10884285, -0.06538936, -0.16720058, -0.01309493],\n",
       "       [-0.01507956,  0.12627214,  0.03250068, -0.18611003,  0.00981596,\n",
       "         0.11106732,  0.2113876 , -0.23930027,  0.00443694,  0.21682683],\n",
       "       [ 0.27879736,  0.05821407,  0.2021912 , -0.18532842, -0.11128481,\n",
       "         0.20442101,  0.23811814,  0.01332703, -0.27333665,  0.17784593],\n",
       "       [ 0.09394956,  0.24046043,  0.09152436,  0.21105018,  0.31458953,\n",
       "         0.200241  , -0.17345528, -0.26579714,  0.24961224, -0.04597169]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .data gets the tensor, and in combination with .numpy() an np array.\n",
    "lin.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 26, 26])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(torch.randn(1,3,28,28)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [torch.nn docs](https://pytorch.org/docs/stable/nn.html) for all the options!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_neural_network = nn.Sequential(nn.Linear(64,32),nn.ReLU(),nn.Linear(32,1),nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4253]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rund tensor through network\n",
    "my_first_neural_network(torch.randn(1,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46016421914100647"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the output with .item()\n",
    "my_first_neural_network(torch.randn(1,64)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight :\n",
      "param: Parameter containing:\n",
      "tensor([[-0.0093, -0.0463,  0.1069,  ...,  0.0947,  0.0879,  0.1144],\n",
      "        [ 0.0679, -0.0387,  0.0425,  ...,  0.0414, -0.0869,  0.0283],\n",
      "        [-0.0541,  0.1098, -0.1088,  ...,  0.0970, -0.0614, -0.0843],\n",
      "        ...,\n",
      "        [-0.0429, -0.0117,  0.0525,  ...,  0.0327,  0.0801, -0.0601],\n",
      "        [-0.0794,  0.0276,  0.0595,  ..., -0.0620,  0.1090, -0.1193],\n",
      "        [-0.1093, -0.0176, -0.1216,  ...,  0.0853,  0.0290, -0.0172]],\n",
      "       requires_grad=True) nparam.grad: None\n",
      "0.bias :\n",
      "param: Parameter containing:\n",
      "tensor([ 0.1182, -0.1228, -0.0830,  0.0449,  0.1234,  0.0594,  0.0204, -0.0440,\n",
      "         0.0409, -0.0403, -0.0034, -0.1128,  0.1031,  0.0096,  0.1211, -0.0984,\n",
      "        -0.0367,  0.0397, -0.0180, -0.0843, -0.1209,  0.0585, -0.0030,  0.0153,\n",
      "         0.0799, -0.0232, -0.1071,  0.0396, -0.0454, -0.1211,  0.0824, -0.0573],\n",
      "       requires_grad=True) nparam.grad: None\n",
      "2.weight :\n",
      "param: Parameter containing:\n",
      "tensor([[ 0.0017, -0.0648, -0.0069, -0.1483, -0.0349,  0.0576, -0.1679, -0.0273,\n",
      "          0.1307, -0.1500, -0.0868, -0.0145, -0.0899, -0.1387,  0.1403,  0.0465,\n",
      "         -0.0259, -0.1112,  0.1460, -0.1460,  0.1340, -0.0861,  0.0089,  0.1072,\n",
      "          0.0689,  0.1166,  0.1714, -0.1722, -0.0096, -0.1169, -0.0955,  0.0134]],\n",
      "       requires_grad=True) nparam.grad: None\n",
      "2.bias :\n",
      "param: Parameter containing:\n",
      "tensor([-0.0132], requires_grad=True) nparam.grad: None\n"
     ]
    }
   ],
   "source": [
    "# print all the parameters and their gradients:\n",
    "for name, param in my_first_neural_network.named_parameters():\n",
    "    print(name,':\\nparam:',param,'nparam.grad:',param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy way to get NN parameters with requires_grad == True\n",
    "param_dict = {name: param for name, param in my_first_neural_network.named_parameters() if param.requires_grad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.weight': Parameter containing:\n",
       " tensor([[-0.0093, -0.0463,  0.1069,  ...,  0.0947,  0.0879,  0.1144],\n",
       "         [ 0.0679, -0.0387,  0.0425,  ...,  0.0414, -0.0869,  0.0283],\n",
       "         [-0.0541,  0.1098, -0.1088,  ...,  0.0970, -0.0614, -0.0843],\n",
       "         ...,\n",
       "         [-0.0429, -0.0117,  0.0525,  ...,  0.0327,  0.0801, -0.0601],\n",
       "         [-0.0794,  0.0276,  0.0595,  ..., -0.0620,  0.1090, -0.1193],\n",
       "         [-0.1093, -0.0176, -0.1216,  ...,  0.0853,  0.0290, -0.0172]],\n",
       "        requires_grad=True), '0.bias': Parameter containing:\n",
       " tensor([ 0.1182, -0.1228, -0.0830,  0.0449,  0.1234,  0.0594,  0.0204, -0.0440,\n",
       "          0.0409, -0.0403, -0.0034, -0.1128,  0.1031,  0.0096,  0.1211, -0.0984,\n",
       "         -0.0367,  0.0397, -0.0180, -0.0843, -0.1209,  0.0585, -0.0030,  0.0153,\n",
       "          0.0799, -0.0232, -0.1071,  0.0396, -0.0454, -0.1211,  0.0824, -0.0573],\n",
       "        requires_grad=True), '2.weight': Parameter containing:\n",
       " tensor([[ 0.0017, -0.0648, -0.0069, -0.1483, -0.0349,  0.0576, -0.1679, -0.0273,\n",
       "           0.1307, -0.1500, -0.0868, -0.0145, -0.0899, -0.1387,  0.1403,  0.0465,\n",
       "          -0.0259, -0.1112,  0.1460, -0.1460,  0.1340, -0.0861,  0.0089,  0.1072,\n",
       "           0.0689,  0.1166,  0.1714, -0.1722, -0.0096, -0.1169, -0.0955,  0.0134]],\n",
       "        requires_grad=True), '2.bias': Parameter containing:\n",
       " tensor([-0.0132], requires_grad=True)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all parameters in a NN\n",
    "for param in my_first_neural_network.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {name: param for name, param in my_first_neural_network.named_parameters() if param.requires_grad}\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze the last layer with gradients\n",
    "my_first_neural_network[-2].weight.requires_grad_(True);\n",
    "my_first_neural_network[-2].bias.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2.weight': Parameter containing:\n",
       " tensor([[ 0.0017, -0.0648, -0.0069, -0.1483, -0.0349,  0.0576, -0.1679, -0.0273,\n",
       "           0.1307, -0.1500, -0.0868, -0.0145, -0.0899, -0.1387,  0.1403,  0.0465,\n",
       "          -0.0259, -0.1112,  0.1460, -0.1460,  0.1340, -0.0861,  0.0089,  0.1072,\n",
       "           0.0689,  0.1166,  0.1714, -0.1722, -0.0096, -0.1169, -0.0955,  0.0134]],\n",
       "        requires_grad=True), '2.bias': Parameter containing:\n",
       " tensor([-0.0132], requires_grad=True)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {name: param for name, param in my_first_neural_network.named_parameters() if param.requires_grad}\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom nn classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal code to sublass nn.Module in PyTorch:\n",
    "```\n",
    "class NewClass(nn.Module):\n",
    "   def __init__(self): # overwritte constructor\n",
    "      super().__init__() # call super class constructor\n",
    "      ...\n",
    "\n",
    "   def forward(self, ...):\n",
    "      ...\n",
    "      return ..`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
