{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 2 - torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on:<br>\n",
    "* [torch.nn tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "* [torch.nn docs](https://pytorch.org/docs/stable/nn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check version number\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if CUDA/GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CUDA/GPU is available print CUDA version\n",
    "if torch.cuda.is_available(): torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class instance\n",
    "lin = nn.Linear(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.1394,  0.0499,  0.0403,  0.2514,  0.0284,  0.2818, -0.0930, -0.1490,\n",
       "          -0.0486, -0.1828],\n",
       "         [-0.0944,  0.2403,  0.1509,  0.2226,  0.0861, -0.0057, -0.2761, -0.1078,\n",
       "          -0.0332, -0.2867],\n",
       "         [ 0.2942, -0.1235, -0.0893, -0.0893,  0.1752,  0.1301, -0.0922, -0.1348,\n",
       "          -0.2011, -0.2492],\n",
       "         [-0.2428, -0.2016, -0.0362,  0.0569, -0.2164,  0.1301, -0.0795, -0.2278,\n",
       "          -0.2559, -0.0671],\n",
       "         [-0.2640,  0.0109,  0.0875,  0.2905,  0.1151,  0.2092, -0.0602,  0.2911,\n",
       "           0.0954, -0.2006]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.2120, -0.1809, -0.2026, -0.1381,  0.2816], requires_grad=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access weights and biases\n",
    "lin.weight, lin.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2379, -0.1646,  0.0473, -0.1541, -0.1795,  0.1025,  0.0527,  0.2035,\n",
       "          0.0800, -0.0874],\n",
       "        [-0.1407,  0.0054,  0.0078,  0.2456, -0.3129, -0.0460,  0.1887,  0.1275,\n",
       "          0.2313,  0.2686],\n",
       "        [-0.0712, -0.2136,  0.1927, -0.2583, -0.2773, -0.0944,  0.0034, -0.2987,\n",
       "         -0.1498,  0.1514],\n",
       "        [ 0.0770,  0.1774, -0.0245, -0.2541, -0.2489, -0.1568,  0.1003,  0.2622,\n",
       "         -0.2504, -0.2198],\n",
       "        [ 0.0106, -0.1580, -0.2525,  0.2910, -0.0370,  0.2523,  0.1660, -0.1993,\n",
       "          0.0585, -0.2405]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add \".data\" to only get the data\n",
    "# .item() gets a Python number from a tensor containing a single value.\n",
    "lin.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(lin.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23786381, -0.1645965 ,  0.04727349, -0.1540767 , -0.17953578,\n",
       "         0.10246778,  0.05267373,  0.2035304 ,  0.08003432, -0.08739886],\n",
       "       [-0.14065963,  0.0054408 ,  0.0078055 ,  0.24562249, -0.31291765,\n",
       "        -0.04602849,  0.18874463,  0.12750387,  0.23134974,  0.26857302],\n",
       "       [-0.07116151, -0.21360278,  0.1927335 , -0.25826943, -0.27726087,\n",
       "        -0.09444   ,  0.00337893, -0.29869476, -0.14975534,  0.15139988],\n",
       "       [ 0.07702318,  0.17735332, -0.02446824, -0.2540539 , -0.2488738 ,\n",
       "        -0.15676379,  0.10031453,  0.26223698, -0.25042427, -0.21981898],\n",
       "       [ 0.01058552, -0.15795133, -0.25250363,  0.29097852, -0.03704199,\n",
       "         0.25232926,  0.166044  , -0.19929628,  0.05854887, -0.24048506]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .data gets the tensor, and in combination with .numpy() an np array.\n",
    "lin.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 26, 26])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(torch.randn(1,3,28,28)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [torch.nn docs](https://pytorch.org/docs/stable/nn.html) for all the options!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_neural_network = nn.Sequential(nn.Linear(64,32),nn.ReLU(),nn.Linear(32,1),nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5647]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run tensor through network\n",
    "my_first_neural_network(torch.randn(1,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5640, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze output to get rank-0 tensor\n",
    "my_first_neural_network(torch.randn(1,64)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output with .item()\n",
    "my_first_neural_network(torch.randn(1,64)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight :\n",
      "param: Parameter containing:\n",
      "tensor([[-0.1235, -0.0776, -0.0610,  ...,  0.0916,  0.0746, -0.1060],\n",
      "        [-0.0233, -0.0515, -0.0584,  ...,  0.0418, -0.0975, -0.1035],\n",
      "        [-0.0341,  0.0495, -0.0390,  ..., -0.0283,  0.0513, -0.0460],\n",
      "        ...,\n",
      "        [-0.0357,  0.1239, -0.0695,  ...,  0.0321, -0.0954,  0.1101],\n",
      "        [ 0.0496, -0.0230,  0.0795,  ...,  0.1218,  0.1227,  0.0270],\n",
      "        [ 0.1110,  0.0312, -0.0408,  ...,  0.0363,  0.1101,  0.0979]],\n",
      "       requires_grad=True) nparam.grad: None\n",
      "0.bias :\n",
      "param: Parameter containing:\n",
      "tensor([-0.1072,  0.0293, -0.1230,  0.0637,  0.0511, -0.0294, -0.0866, -0.0430,\n",
      "        -0.0413, -0.0589,  0.0043, -0.0906,  0.0062, -0.0553, -0.0051, -0.0693,\n",
      "         0.1203,  0.1058,  0.0142,  0.0726,  0.0804,  0.0819,  0.0177,  0.0371,\n",
      "         0.0147, -0.0824,  0.0406, -0.1154,  0.1220,  0.0925, -0.1125, -0.0042],\n",
      "       requires_grad=True) nparam.grad: None\n",
      "2.weight :\n",
      "param: Parameter containing:\n",
      "tensor([[-0.1486, -0.0795, -0.0716,  0.0629, -0.0544,  0.0718, -0.1625, -0.1192,\n",
      "         -0.0579, -0.0227,  0.1214, -0.1168,  0.1385, -0.0454, -0.0547, -0.1180,\n",
      "          0.0825, -0.0096, -0.1004, -0.0854, -0.0659, -0.1035,  0.1126, -0.1017,\n",
      "          0.0130,  0.0360, -0.1637,  0.1634,  0.0767, -0.1760,  0.0429, -0.1716]],\n",
      "       requires_grad=True) nparam.grad: None\n",
      "2.bias :\n",
      "param: Parameter containing:\n",
      "tensor([0.0449], requires_grad=True) nparam.grad: None\n"
     ]
    }
   ],
   "source": [
    "# print all the parameters and their gradients:\n",
    "for name, param in my_first_neural_network.named_parameters():\n",
    "    print(name,':\\nparam:',param,'nparam.grad:',param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy way to get NN parameters with requires_grad == True\n",
    "param_dict = {name: param for name, param in my_first_neural_network.named_parameters() if param.requires_grad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.weight': Parameter containing:\n",
       " tensor([[-0.1235, -0.0776, -0.0610,  ...,  0.0916,  0.0746, -0.1060],\n",
       "         [-0.0233, -0.0515, -0.0584,  ...,  0.0418, -0.0975, -0.1035],\n",
       "         [-0.0341,  0.0495, -0.0390,  ..., -0.0283,  0.0513, -0.0460],\n",
       "         ...,\n",
       "         [-0.0357,  0.1239, -0.0695,  ...,  0.0321, -0.0954,  0.1101],\n",
       "         [ 0.0496, -0.0230,  0.0795,  ...,  0.1218,  0.1227,  0.0270],\n",
       "         [ 0.1110,  0.0312, -0.0408,  ...,  0.0363,  0.1101,  0.0979]],\n",
       "        requires_grad=True), '0.bias': Parameter containing:\n",
       " tensor([-0.1072,  0.0293, -0.1230,  0.0637,  0.0511, -0.0294, -0.0866, -0.0430,\n",
       "         -0.0413, -0.0589,  0.0043, -0.0906,  0.0062, -0.0553, -0.0051, -0.0693,\n",
       "          0.1203,  0.1058,  0.0142,  0.0726,  0.0804,  0.0819,  0.0177,  0.0371,\n",
       "          0.0147, -0.0824,  0.0406, -0.1154,  0.1220,  0.0925, -0.1125, -0.0042],\n",
       "        requires_grad=True), '2.weight': Parameter containing:\n",
       " tensor([[-0.1486, -0.0795, -0.0716,  0.0629, -0.0544,  0.0718, -0.1625, -0.1192,\n",
       "          -0.0579, -0.0227,  0.1214, -0.1168,  0.1385, -0.0454, -0.0547, -0.1180,\n",
       "           0.0825, -0.0096, -0.1004, -0.0854, -0.0659, -0.1035,  0.1126, -0.1017,\n",
       "           0.0130,  0.0360, -0.1637,  0.1634,  0.0767, -0.1760,  0.0429, -0.1716]],\n",
       "        requires_grad=True), '2.bias': Parameter containing:\n",
       " tensor([0.0449], requires_grad=True)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all parameters in a NN\n",
    "for param in my_first_neural_network.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {name: param for name, param in my_first_neural_network.named_parameters() if param.requires_grad}\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_neural_network[1] = nn.SELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (1): SELU()\n",
       "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_first_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze the last layer with gradients\n",
    "my_first_neural_network[-2].weight.requires_grad_(True);\n",
    "my_first_neural_network[-2].bias.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2.weight': Parameter containing:\n",
       " tensor([[-0.1486, -0.0795, -0.0716,  0.0629, -0.0544,  0.0718, -0.1625, -0.1192,\n",
       "          -0.0579, -0.0227,  0.1214, -0.1168,  0.1385, -0.0454, -0.0547, -0.1180,\n",
       "           0.0825, -0.0096, -0.1004, -0.0854, -0.0659, -0.1035,  0.1126, -0.1017,\n",
       "           0.0130,  0.0360, -0.1637,  0.1634,  0.0767, -0.1760,  0.0429, -0.1716]],\n",
       "        requires_grad=True), '2.bias': Parameter containing:\n",
       " tensor([0.0449], requires_grad=True)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {name: param for name, param in my_first_neural_network.named_parameters() if param.requires_grad}\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Udacity DL PyTorch weight init notebook](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/weight-initialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linear', 'ReLU', 'Linear', 'Sigmoid']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.__class__.__name__ for m in my_first_neural_network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization (from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.normal_(m.bias.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the weights_init function to initialize all weights\n",
    "my_first_neural_network.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom nn classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal code to sublass nn.Module in PyTorch:\n",
    "```\n",
    "class NewClass(nn.Module):\n",
    "   def __init__(self): # overwritte constructor\n",
    "      super().__init__() # call super class constructor\n",
    "      ...\n",
    "\n",
    "   def forward(self, ...):\n",
    "      ...\n",
    "      return ..`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/huggingface/pytorch-openai-transformer-lm/blob/master/model_pytorch.py\n",
    "class GeLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gelu = GeLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1478, -0.0914,  0.1858],\n",
       "        [-0.1656,  0.1073, -0.0489],\n",
       "        [ 0.3415, -0.1373, -0.0405],\n",
       "        [ 0.3330, -0.1672, -0.0821],\n",
       "        [ 0.6911,  0.7304,  1.3309],\n",
       "        [-0.0269,  0.2888,  1.0044]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu(torch.randn(6,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.functional or F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://discuss.pytorch.org/t/whats-the-difference-between-torch-nn-functional-and-torch-nn/681/2?u=micpie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze operation removes dimensions/axis with length 1:\n",
    "torch.randn(3,1,5,1,1).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this can be also achieved with .view:\n",
    "torch.randn(3,1,5,1,1).view(3,5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
